{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style(\"dark\")\n",
    "sns.set_palette(plt.viridis())\n",
    "\n",
    "import cv2 as cv\n",
    "import brisque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_view = 'KL11-E1DC'\n",
    "base_path = '../../data/real/'\n",
    "availible_ids = [int(file.split('.')[0])\n",
    "                 for file in os.listdir(f\"../../data/real/{camera_view}/\") \n",
    "                 if file.endswith(\".png\")]\n",
    "\n",
    "imgbank = {id_: cv.imread(os.path.join(base_path, camera_view, str(id_) + '.png'), cv.IMREAD_GRAYSCALE)\n",
    "          for id_ in availible_ids}\n",
    "\n",
    "imgbank_ds = {id_: cv.pyrDown(img) for id_, img in imgbank.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out downsampled copies of all images\n",
    "#[cv.imwrite(os.path.join(base_path, camera_view, 'ds', str(id_) + '.png'), cv.pyrDown(img)) for id_, img in imgbank.items() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_n(imgs, ids, n, title):\n",
    "    fig = plt.figure(1, figsize=(14.5,8))\n",
    "    \n",
    "    for i in range(n):\n",
    "        plt.subplot(200 + 10*n/2 + 1 + i)\n",
    "        plt.imshow(imgs[i], vmin=0, vmax=255)\n",
    "        ax = plt.gca()\n",
    "        ax.tick_params(\n",
    "                bottom=False,\n",
    "                left=False,\n",
    "                labelbottom=False,\n",
    "                labelleft=False)\n",
    "        plt.title(ids[i])\n",
    "        \n",
    "    fig.suptitle(title, fontsize=15, weight=600)\n",
    "    #fig.subplots_adjust(hspace=0.01, wspace=0.005)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    fig.subplots_adjust(hspace=0.0, wspace=0.0)\n",
    "    plt.show()\n",
    "    \n",
    "def get_imgs_from_dict(ids, ds=False):\n",
    "    if ds:\n",
    "        return [imgbank_ds[id_] for id_ in ids]\n",
    "    else:\n",
    "        return [imgbank[id_] for id_ in ids]\n",
    "    \n",
    "    \n",
    "def show_metric(df, metric, lowest, downsampled, n=8):\n",
    "    sorted_df = df[metric].sort_values()\n",
    "    \n",
    "    if lowest:\n",
    "        low = sorted_df[:n].index\n",
    "        plot_n(get_imgs_from_dict(low, downsampled), low, n, f'ds={downsampled} - lowest {metric}')\n",
    "    if not lowest:\n",
    "        hi = sorted_df[-n:].index[::-1]\n",
    "        plot_n(get_imgs_from_dict(hi, downsampled), hi, n, f'ds={downsampled} - highest {metric}')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "Calculate and add to a common df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brisque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the lower the BRISQUE the better the image looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brisq = brisque.BRISQUE()\n",
    "scores = {id_: brisq.get_score(os.path.join(base_path, camera_view, str(id_) + '.png')) \n",
    "          for id_ in imgbank.keys()}\n",
    "\n",
    "scores_ds = {id_: brisq.get_score(os.path.join(base_path, camera_view, 'ds', str(id_) + '.png')) \n",
    "             for id_ in imgbank_ds.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(scores, orient='index', columns=['brisque'])\n",
    "df.index.name = 'id'\n",
    "\n",
    "df_ds = pd.DataFrame.from_dict(scores_ds, orient='index', columns=['brisque'])\n",
    "df_ds.index.name = 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take top/bottom n images \n",
    "n = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_metric(df, 'brisque', lowest=True, downsampled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_metric(df, 'brisque', lowest=False, downsampled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BRISQUE definitely looks like it is capturing some information about overall image 'quality' - above and beyond just noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df_ds, 'brisque', lowest=True, downsampled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df_ds, 'brisque', lowest=False, downsampled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the DS images, BRISQUE seems to rate highly images with a high dynamic range, and rate poorly images that are more washed out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram based\n",
    "\n",
    "Just mean and var for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hist_mean_var(image):\n",
    "    #Â note there is actually no need to get a histogram first - we can do this directly\n",
    "    n, bins = np.histogram(image.flatten(), 255, density=True)\n",
    "\n",
    "    mids = 0.5*(bins[1:] + bins[:-1])\n",
    "    mean = np.average(mids, weights=n)\n",
    "    var = np.average((mids - mean)**2, weights=n)\n",
    "\n",
    "    return n, mean, var**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "sigmas = []\n",
    "\n",
    "means_ds = []\n",
    "sigmas_ds = []\n",
    "\n",
    "for id_ in availible_ids:\n",
    "    img = imgbank[id_]\n",
    "    img_ds = imgbank_ds[id_]\n",
    "    \n",
    "    hist, mean, sigma = get_hist_mean_var(img)\n",
    "    hist_ds, mean_ds, sigma_ds = get_hist_mean_var(img_ds)\n",
    "   \n",
    "    means.append(mean)\n",
    "    sigmas.append(sigma)\n",
    "    \n",
    "    means_ds.append(mean_ds)\n",
    "    sigmas_ds.append(sigma_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hist_mean'] = means\n",
    "df['hist_sigma'] = sigmas\n",
    "\n",
    "maxs = {id_: img.max() for id_, img in imgbank.items()}\n",
    "mins = {id_: img.min() for id_, img in imgbank.items()}\n",
    "\n",
    "df['hist_max'] = pd.Series(maxs)\n",
    "df['hist_min'] = pd.Series(mins)\n",
    "df['hist_range'] = df['hist_max'] - df['hist_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ds['hist_mean'] = means_ds\n",
    "df_ds['hist_sigma'] = sigmas_ds\n",
    "\n",
    "maxs_ds = {id_: img.max() for id_, img in imgbank_ds.items()}\n",
    "mins_ds = {id_: img.min() for id_, img in imgbank_ds.items()}\n",
    "\n",
    "df_ds['hist_max'] = pd.Series(maxs_ds)\n",
    "df_ds['hist_min'] = pd.Series(mins_ds)\n",
    "df_ds['hist_range'] = df_ds['hist_max'] - df_ds['hist_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df, 'hist_mean', lowest=True, downsampled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df, 'hist_mean', lowest=False, downsampled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max and mins of histogram means does what you would expect - although due to high noise there is actually not a large difference between the extremes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hist_mean'].min(), df['hist_mean'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df_ds, 'hist_mean', lowest=True, downsampled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df_ds, 'hist_mean', lowest=False, downsampled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ds['hist_mean'].min(), df_ds['hist_mean'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> After DS however, the difference is night and day. We can effective separate over and under exposed images. \n",
    "\n",
    "I said before realising that plt.imshow will automatically change the colour mapping based on the limits of the input data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df, 'hist_sigma', lowest=True, downsampled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df, 'hist_sigma', lowest=False, downsampled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at histogram variance, as expected, gives information about contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df_ds, 'hist_sigma', lowest=True, downsampled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df_ds, 'hist_sigma', lowest=False, downsampled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the differences look much clearer after downsampling: the low variances images, whether they are bright or dark, are mostly one thing (i.e. the whole image is dim or the whole image is bright). Meanwhile, at the high end, we get images with bright regions, and also dark regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick and dirty way of quantifying noise is taking\n",
    "\n",
    "$$\\langle|image - smoothing(image)|\\rangle$$\n",
    "\n",
    "Tried this with three different smoothing filters to see which would give the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(img):\n",
    "    smooth = cv.medianBlur(img,5)\n",
    "    \n",
    "    diff = np.abs(img.astype(int) - smooth.astype(int))\n",
    "    return diff.mean(), diff.std()\n",
    "\n",
    "\n",
    "def get_noise_bl(img):\n",
    "    smooth = cv.bilateralFilter(img, d=3,\n",
    "                            sigmaColor=50,\n",
    "                            sigmaSpace=50)\n",
    "    \n",
    "    diff = np.abs(img.astype(int) - smooth.astype(int))\n",
    "    return diff.mean(), diff.std()\n",
    "\n",
    "\n",
    "def get_noise_nlm(img):\n",
    "    smooth = cv.fastNlMeansDenoising(img, h=5, searchWindowSize=3)\n",
    "    \n",
    "    diff = np.abs(img.astype(int) - smooth.astype(int))\n",
    "    return diff.mean(), diff.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_mean = np.array([get_noise(img)[0] for img in imgbank.values()]).mean()\n",
    "med_std = np.array([get_noise(img)[0] for img in imgbank.values()]).std()\n",
    "\n",
    "med_mean_ds = np.array([get_noise(img)[0] for img in imgbank_ds.values()]).mean()\n",
    "med_std_ds = np.array([get_noise(img)[0] for img in imgbank_ds.values()]).std()\n",
    "\n",
    "print(f'full image mean: {med_mean:.3f} +/- {med_std:.2f}')\n",
    "print(f'ds image mean: {med_mean_ds:.3f} +/- {med_std_ds:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_mean = np.array([get_noise_bl(img)[0] for img in imgbank.values()]).mean()\n",
    "bl_std = np.array([get_noise_bl(img)[0] for img in imgbank.values()]).std()\n",
    "\n",
    "bl_mean_ds = np.array([get_noise_bl(img)[0] for img in imgbank_ds.values()]).mean()\n",
    "bl_std_ds = np.array([get_noise_bl(img)[0] for img in imgbank_ds.values()]).std()\n",
    "\n",
    "print(f'full image mean: {bl_mean:.3f} +/- {bl_std:.2f}')\n",
    "print(f'ds image mean: {bl_mean_ds:.3f} +/- {bl_std_ds:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlm_mean = np.array([get_noise_nlm(img)[0] for img in imgbank.values()]).mean()\n",
    "nlm_std = np.array([get_noise_nlm(img)[0] for img in imgbank.values()]).std()\n",
    "\n",
    "nlm_mean_ds = np.array([get_noise_nlm(img)[0] for img in imgbank_ds.values()]).mean()\n",
    "nlm_std_ds = np.array([get_noise_nlm(img)[0] for img in imgbank_ds.values()]).std()\n",
    "\n",
    "print(f'full image mean: {nlm_mean:.3f} +/- {nlm_std:.2f}')\n",
    "print(f'ds image mean: {nlm_mean_ds:.3f} +/- {nlm_std_ds:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,4))\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.set_xticks([-1, 0, 1])\n",
    "ax.set_xticklabels(['median', 'bl', 'nlm'])\n",
    "\n",
    "\n",
    "plt.errorbar([-1, -1], [med_mean, med_mean_ds], \n",
    "             yerr=[med_std, med_std_ds], fmt='o')\n",
    "plt.errorbar([0, 0], [bl_mean, bl_mean_ds], \n",
    "             yerr=[bl_std, bl_std_ds], fmt='o')\n",
    "plt.errorbar([1, 1], [nlm_mean, nlm_mean_ds], \n",
    "             yerr=[nlm_std, nlm_std_ds], fmt='o')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's use the bilateral based thing - though maybe median is a better choice as it's probably more efficient..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = []\n",
    "noises_ds = []\n",
    "\n",
    "for id_ in availible_ids:\n",
    "    img = imgbank[id_]\n",
    "    img_ds = imgbank_ds[id_]\n",
    "    \n",
    "    noise = get_noise_bl(img)[0]\n",
    "    noise_ds = get_noise_bl(img_ds)[0]\n",
    "    \n",
    "    noises.append(noise)\n",
    "    noises_ds.append(noise)\n",
    "    \n",
    "df['noise_bl'] = noises\n",
    "df_ds['noise_bl'] = noises_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df, 'noise_bl', lowest=True, downsampled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df, 'noise_bl', lowest=False, downsampled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitely working as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df_ds, 'noise_bl', lowest=True, downsampled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df_ds, 'noise_bl', lowest=False, downsampled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference is less pronunced, because we have already removed a lot of the noise in the DS step, but still looks useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blur(img):      \n",
    "    return -cv.Laplacian(img, cv.CV_64F).var()\n",
    "\n",
    "blurs = []\n",
    "blurs_ds = []\n",
    "\n",
    "for id_ in availible_ids:\n",
    "    img = imgbank[id_]\n",
    "    img_ds = imgbank_ds[id_]\n",
    "    \n",
    "    blur = get_blur(img)\n",
    "    blur_ds = get_blur(img_ds)\n",
    "    \n",
    "    blurs.append(blur)\n",
    "    blurs_ds.append(blur_ds)\n",
    "    \n",
    "df['blur'] = blurs\n",
    "df_ds['blur'] = blurs_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df, 'blur', lowest=True, downsampled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df, 'blur', lowest=False, downsampled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df_ds, 'blur', lowest=True, downsampled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df_ds, 'blur', lowest=False, downsampled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g,d,b='good','decent','bad'\n",
    "#redo\n",
    "eyeball = pd.Series([b,b,b,b,b,b,b,g,g,b,\n",
    "                     g,g,g,b,g,g,g,g,g,g,\n",
    "                     b,b,g,b,g,b,b,b,b,g,\n",
    "                     g,b,g,g,g,b,b,g,g,g,\n",
    "                     g,b,g,g,g,b,g,g,b,g,\n",
    "                     b,b,b,b,b,g,b,b,g,b,\n",
    "                     g,b,g,b,b,b,b,g,g,b,\n",
    "                     b,g,b,b,g,g,g,b,b,b,\n",
    "                     g,b,g,b,b,g,b,g,b,g,\n",
    "                     b,g,b,b,b,b,g,b,g,g,#\n",
    "                     b,g,b,g,b,g,g,b,b],\n",
    "                     index=availible_ids)\n",
    "\n",
    "df['subjective_category'] = eyeball\n",
    "g = sns.pairplot(df, hue='subjective_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_ds['subjective_category'] = eyeball\n",
    "g = sns.pairplot(df_ds, hue='subjective_category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def normalize_df(df, dropminmax=True, dropmean=True):\n",
    "    \n",
    "    df = df.drop(columns='subjective_category')\n",
    "    \n",
    "    if dropminmax:\n",
    "        df = df.drop(columns=['hist_min', 'hist_max'])\n",
    "    if dropmean:\n",
    "        df = df.drop(columns='hist_mean')\n",
    "    \n",
    "    min_max_scaler = preprocessing.MinMaxScaler((0,100))\n",
    "\n",
    "    df_scaled = pd.DataFrame(min_max_scaler.fit_transform(df), columns=df.columns, index=df.index)\n",
    "    \n",
    "    return df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize_df(df).values\n",
    "nbrs = NearestNeighbors(n_neighbors=8).fit(X)\n",
    "distances, indices = nbrs.kneighbors(X)\n",
    "\n",
    "argmax = distances.mean(axis=1).argmax()\n",
    "argmin = distances.mean(axis=1).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dist = df.index[indices[argmax]].values\n",
    "dists = distances[argmax]\n",
    "titles = list(zip(max_dist,np.around(dists)))\n",
    "plot_n(get_imgs_from_dict(max_dist, ds=False), titles, 8, 'Furthest Neighbours to top left (id, dist)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dist = df.index[indices[argmin]].values\n",
    "dists = distances[argmin]\n",
    "titles = list(zip(min_dist,np.around(dists)))\n",
    "plot_n(get_imgs_from_dict(min_dist, ds=False), titles, 8, 'Closest Neighbours to top left (id, dist)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize_df(df_ds).values\n",
    "nbrs = NearestNeighbors(n_neighbors=8).fit(X)\n",
    "distances, indices = nbrs.kneighbors(X)\n",
    "\n",
    "argmax = distances.mean(axis=1).argmax()\n",
    "argmin = distances.mean(axis=1).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dist = df_ds.index[indices[argmax]].values\n",
    "dists = distances[argmax]\n",
    "titles = list(zip(max_dist,np.around(dists)))\n",
    "plot_n(get_imgs_from_dict(max_dist, ds=True), titles, 8, 'DS Furthest Neighbours to top left (id, dist)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dist = df_ds.index[indices[argmin]].values\n",
    "dists = distances[argmin]\n",
    "titles = list(zip(min_dist,np.around(dists)))\n",
    "plot_n(get_imgs_from_dict(min_dist, ds=True), titles, 8, 'DS Closest Neighbours to top left (id, dist)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same thing again but select neighbours within a radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize_df(df, False, False).values\n",
    "nbrs = NearestNeighbors(n_neighbors=8).fit(X)\n",
    "distances, indices = nbrs.radius_neighbors(radius=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('for each image, number of images within 15 units of it')\n",
    "np.array([c.shape[0] for c in indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = normalize_df(df).values\n",
    "X_ds = normalize_df(df_ds).values\n",
    "\n",
    "model = PCA(n_components=2)\n",
    "model.fit(X)\n",
    "X_2D = model.transform(X)\n",
    "\n",
    "model_ds = PCA(n_components=2)\n",
    "model.fit(X_ds)\n",
    "X_2D_ds = model.transform(X_ds)\n",
    "\n",
    "df_ = df.copy()\n",
    "df_['PCA1'] = X_2D[:, 0]\n",
    "df_['PCA2'] = X_2D[:, 1]\n",
    "\n",
    "df_ds_ = df_ds.copy()\n",
    "df_ds_['PCA1'] = X_2D_ds[:, 0]\n",
    "df_ds_['PCA2'] = X_2D_ds[:, 1]\n",
    "\n",
    "def f(x):\n",
    "    if x == 'bad':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "c = list(map(f, list(df_['subjective_category'].values)))\n",
    "c_ds = list(map(f, list(df_ds_['subjective_category'].values)))\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "plt.scatter(X_2D[:, 0], X_2D[:, 1], c=c)\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.title('Full res')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(X_2D_ds[:, 0], X_2D_ds[:, 1], c=c_ds)\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.title('Downsampeld')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There could be interesting stats to be done here, but we need more images to come to any conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering doesn't make sense. Consider an image. If the image has low contrast, we need to boost the contrast a lot, introducing a lot of noise. Then we have to strongly denoise it after based on its new noise profile. It is not obvious that we would be able to know in advance how much denoising we would need based on the initial information in the image. Rather, each stage should analyse the image as it is currently and decide what preprocessing to employ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.mean(), columns=['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single(img_id, df):\n",
    "    titles = df.mean().index\n",
    "    means = df.mean().values\n",
    "    \n",
    "    this_df = pd.DataFrame(df.mean(), columns=['mean'])\n",
    "    \n",
    "    this_df['max'] = df.max()\n",
    "    this_df['min'] = df.min()\n",
    "    \n",
    "    this_df[str(img_id)] = df.loc[img_id]\n",
    "    this_df = this_df.T\n",
    "    \n",
    "    this_df['source'] = ['mean', 'max', 'min', 'this']\n",
    "    \n",
    "    return this_df\n",
    "\n",
    "\n",
    "plot_single(90112, df)\n",
    "sns.pairplot(plot_single(availible_ids[0], df), hue='source')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrast\n",
    "\n",
    "assumption in testing: we can map the detected contrast in an image to the amount of cc that needs to be applied independenrt of other params (note we can actually relax this assumption by just taking those things into account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_contrast(img, clip_limit, n_tiles_per_row):\n",
    "\n",
    "    # create the object\n",
    "    clahe = cv.createCLAHE(clipLimit=clip_limit, \n",
    "                            tileGridSize=(n_tiles_per_row, n_tiles_per_row))\n",
    "    \n",
    "    # apply equalisation\n",
    "    return clahe.apply(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df_ds, 'hist_sigma', lowest=True, downsampled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_sigma = df_ds['hist_sigma'].sort_values()\n",
    "\n",
    "clip_limits = 1 / (sorted_by_sigma[:n]**3.2 / 1e5 * 1.5)\n",
    "clip_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ds.loc[clip_limits.index]['hist_sigma'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = sorted_by_sigma[:n].index\n",
    "imgs = get_imgs_from_dict(hi, ds=True)\n",
    "\n",
    "imgs_cc = [correct_contrast(img, clip+1.6, 10) for img, clip in zip(imgs, clip_limits)]\n",
    "\n",
    "plot_n(imgs_cc, hi, n, 'DS low hist_sigma contrast corrected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metric(df_ds, 'hist_sigma', lowest=False, downsampled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_limits = 1 / (sorted_by_sigma[:n]**3.2 / 1e5 * 2)\n",
    "clip_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[hi]['hist_sigma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_sigma = df_ds['hist_sigma'].sort_values()\n",
    "hi = sorted_by_sigma[-n:].index[::-1]\n",
    "imgs = get_imgs_from_dict(hi, ds=True)\n",
    "\n",
    "imgs_cc = [correct_contrast(img, 2, 10) for img, clip in zip(imgs, clip_limits)]\n",
    "\n",
    "plot_n(imgs_cc, hi, n, 'DS high hist_sigma contrast corrected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some kind of inconsistencies here, check with other metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just noticed this iamge seems to contain motion blur straight up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(correct_contrast(get_imgs_from_dict([89065], ds=True)[0], 10, 10), vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerically fitted exponential\n",
    "def get_clip_lim(hist_sigma):\n",
    "    clip_lim = 0.3691732 + 111.0668*np.exp(-0.1625793*hist_sigma)\n",
    "    return clip_lim + 1.6\n",
    "\n",
    "# numerically fitted sigmoid\n",
    "def get_tile_size(hist_sigma):\n",
    "    tile_size = 9.945744 + (19.95339 - 9.945744)/(1 + (hist_sigma/36.68951)**38.40906)\n",
    "    return int(tile_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_ds['hist_sigma'].sort_values().iloc[np.linspace(0, len(df_ds)-1, 8).astype(int)]\n",
    "\n",
    "clip_lims = [get_clip_lim(hist_sigma) for hist_sigma in sample.values]\n",
    "tile_sizes = [get_tile_size(hist_sigma) for hist_sigma in sample.values]\n",
    "\n",
    "imgs = get_imgs_from_dict(sample.index, ds=True)\n",
    "imgs_cc = [correct_contrast(img, clip_lim, tile_size) \n",
    "           for img, clip_lim, tile_size in zip(imgs, clip_lims, tile_sizes)]\n",
    "\n",
    "plot_n(imgs_cc, sample.index, 8, 'Corrected scan accross hist_sigma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bearing in mind the original images, below, this is a pretty decent result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_n(imgs, sample.index, 8, 'Scan accross image hist_sigma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First apply this CC accross all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_limits = df_ds['hist_sigma'].map(get_clip_lim)\n",
    "tile_sizes = df_ds['hist_sigma'].map(get_tile_size)\n",
    "imgs = get_imgs_from_dict(df_ds.index, ds=True)\n",
    "\n",
    "imgs_cc = [correct_contrast(img, clip_lim, tile_size) \n",
    "           for img, clip_lim, tile_size in zip(imgs, clip_limits, tile_sizes)]\n",
    "imgbank_cc = {id_: img_cc for id_, img_cc in zip(availible_ids, imgs_cc)}\n",
    "\n",
    "len(imgs_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noises_after_cc = [get_noise_bl(img_cc)[0] for img_cc in imgs_cc]\n",
    "df_ds['noise_after_cc'] = noises_after_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_ds['noise_bl'], bins=20, range=(0,12), label='Before CC', histtype='step', linewidth=3)\n",
    "plt.hist(df_ds['noise_after_cc'], bins=20, range=(0,12), label='After CC', histtype='step', linewidth=3)\n",
    "plt.xlabel('Noise')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_sigmas_after_cc = [get_hist_mean_var(img_cc)[2] for img_cc in imgs_cc]\n",
    "df_ds['hist_sigma_after_cc'] = hist_sigmas_after_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_ds['hist_sigma'], bins=20, range=(25,50), label='Before CC', histtype='step', linewidth=3)\n",
    "plt.hist(df_ds['hist_sigma_after_cc'], bins=20, range=(25,50), label='After CC', histtype='step', linewidth=3)\n",
    "plt.xlabel('hist_sigma')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprising results. Investigate this further by recalculating all image metrics at every step and seeing what is actually changing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoise After CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap opencv functions so they are compatible with plots\n",
    "def bilateral_filter(img, filter_size=5, sigma=70):\n",
    "    \n",
    "    # it's not clear exactly what the parameters represent in the docs...\n",
    "    # (the sigmaSpace parameter appears to be superfluous)\n",
    "    return cv.bilateralFilter(img, d=filter_size,\n",
    "                               sigmaColor=sigma,\n",
    "                               sigmaSpace=sigma)\n",
    "\n",
    "def nlm_filter(img, strength=2.5, window_size=6):\n",
    "    return cv.fastNlMeansDenoising(img, h=strength, searchWindowSize=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_noise = df_ds['noise_after_cc'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = sorted_by_noise[-n:].index.values[::-1]\n",
    "imgs = [imgbank_cc[id_] for id_ in hi]\n",
    "\n",
    "plot_n(imgs, hi, n, 'DS highest noise after contrast corrected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_bl = [bilateral_filter(img, 30, 10) for img in imgs]\n",
    "\n",
    "plot_n(imgs_bl, hi, n, 'DS highest noise after contrast corrected > denoised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "47.2727px",
    "left": "30.9943px",
    "top": "66.2926px",
    "width": "159.162px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
